import folktexts
import pandas as pd

from folktexts.col_to_text import ColumnToText
from folktexts.task import TaskMetadata
from folktexts.qa_interface import DirectNumericQA
from folktexts.qa_interface import MultipleChoiceQA, Choice
from folktexts.classifier import WebAPILLMClassifier
from folktexts.benchmark import BenchmarkConfig, Benchmark
from folktexts.dataset import Dataset
import os


TASK_DESCRIPTION = """
The data are MC generated (see below) to simulate registration of high energy
gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the
imaging technique. Cherenkov gamma telescope observes high energy gamma rays,
taking advantage of the radiation emitted by charged particles produced
inside the electromagnetic showers initiated by the gammas, and developing in the
atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks
through the atmosphere and gets recorded in the detector, allowing reconstruction
of the shower parameters. The available information consists of pulses left by
the incoming Cherenkov photons on the photomultiplier tubes, arranged in a
plane, the camera. Depending on the energy of the primary gamma, a total of
few hundreds to some 10000 Cherenkov photons get collected, in patterns
(called the shower image), allowing to discriminate statistically those
caused by primary gammas (signal) from the images of hadronic showers
initiated by cosmic rays in the upper atmosphere (background).

Typically, the image of a shower after some pre-processing is an elongated
cluster. Its long axis is oriented towards the camera center if the shower axis
is parallel to the telescope's optical axis, i.e. if the telescope axis is
directed towards a point source. A principal component analysis is performed
in the camera plane, which results in a correlation axis and defines an ellipse.
If the depositions were distributed as a bivariate Gaussian, this would be
an equidensity ellipse. The characteristic parameters of this ellipse
(often called Hillas parameters) are among the image parameters that can be
used for discrimination. The energy depositions are typically asymmetric
along the major axis, and this asymmetry can also be used in discrimination.
There are, in addition, further discriminating characteristics, like the
extent of the cluster in the image plane, or the total sum of depositions.

The data set was generated by a Monte Carlo program, Corsika, described in
D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,
Forschungszentrum Karlsruhe FZKA 6019 (1998).
The program was run with parameters allowing to observe events with energies down
to below 50 GeV.

Please answer each question based on the information provided. \
The data provided is enough to reach an approximate answer for each person.
"""

"""COLUMNS"""
fLength = ColumnToText(
    "fLength",
    short_description="major axis of ellipse [mm]",
    value_map=lambda x: f"{x} mm",
)

fWidth = ColumnToText(
    "fWidth",
    short_description="minor axis of ellipse [mm]",
    value_map=lambda x: f"{x} mm"
)

fSize = ColumnToText(
    "fSize",
    short_description="10-log of sum of content of all pixels [in #phot]",
    value_map=lambda x: f"{x} phot"
)

fConc = ColumnToText(
    "fConc",
    short_description="ratio of sum of two highest pixels over fSize [ratio]",
    value_map=lambda x: f"{x}"
)

fConc = ColumnToText(
    "fConc1",
    short_description="ratio of highest pixel over fSize [ratio]",
    value_map=lambda x: f"{x}"
)

fAsym = ColumnToText(
    "fAsym",
    short_description="distance from highest pixel to center, projected onto major axis [mm]",
    value_map=lambda x: f"{x} mm"
)

fM3Long = ColumnToText(
    "fM3Long",
    short_description="3rd root of third moment along major axis [mm]",
    value_map=lambda x: f"{x} mm"
)

fM3Trans = ColumnToText(
    "fM3Trans",
    short_description="3rd root of third moment along minor axis [mm]",
    value_map=lambda x: f"{x} mm"
)

fM3Trans = ColumnToText(
    "fAlpha",
    short_description="angle of major axis with vector to origin [deg]",
    value_map=lambda x: f"{x} deg"
)

fDist = ColumnToText(
    "fDist",
    short_description="distance from origin to center of ellipse [mm]",
    value_map=lambda x: f"{x} mm"
)

class_binary = ColumnToText(
    "class_binary",
    short_description="gamma (signal), hadron (background)",
    value_map={
        0: "g",
        1: "h"
    }
)

columns_map: dict[str, object] = {
    col_mapper.name: col_mapper
    for col_mapper in globals().values()
    if isinstance(col_mapper, ColumnToText)
}

reentry_numeric_qa = DirectNumericQA(
    column='class_binary',
    text=(
        "Is the observation caused by primary gammas (signal)?"
    ),
)


reentry_qa = MultipleChoiceQA(
    column='class_binary',
    text="Is the observation caused by primary gammas (signal)?",
    choices=(
        Choice("Yes, it is", 1),
        Choice("No, it is hadronic (background)", 0),
    ),
)



all_outcomes = ["class_binary"]

reentry_task = TaskMetadata(
    name="class prediction",
    description=TASK_DESCRIPTION,
    features=[x for x in columns_map.keys() if x not in all_outcomes],
    target='class_binary',
    cols_to_text=columns_map,
    sensitive_attribute=None,
    multiple_choice_qa=reentry_qa,
    direct_numeric_qa=reentry_numeric_qa,
)


data = pd.read_csv("data/telescope_data_binary.csv")
num_data = len(data)
# we want to sample 5k
subsampling = (5000 / 0.95) / num_data

reentry_dataset = Dataset(
    data=data,
    task=reentry_task,
    test_size=0.95,
    val_size=0,
    subsampling=subsampling,   # NOTE: Optional, for faster but noisier results!
)

all_tasks = {
    "reentry": [reentry_task, reentry_dataset]
}

model_name = "openai/gpt-4o-mini"
import os
import json
with open("secrets.json", "r") as handle:
    os.environ["OPENAI_API_KEY"] = json.load(handle)["open_ai_key"]
    
for taskname in all_tasks:
    task, dataset = all_tasks[taskname]
    llm_clf = WebAPILLMClassifier(model_name=model_name, task=task, custom_prompt_prefix=TASK_DESCRIPTION)  
    llm_clf.set_inference_kwargs(batch_size=500)
    bench = Benchmark(llm_clf=llm_clf, dataset=dataset)

    RESULTS_DIR = "telescope"
    bench.run(results_root_dir=RESULTS_DIR)


